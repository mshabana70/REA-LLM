HELLO
HELLO2
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
There was a problem when trying to write in your cache folder (/data). You should set the environment variable TRANSFORMERS_CACHE to a writable directory.
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Traceback (most recent call last):

  File "/opt/conda/bin/text-generation-server", line 8, in <module>
    sys.exit(app())

  File "/opt/conda/lib/python3.9/site-packages/text_generation_server/cli.py", line 128, in download_weights
    adapter_config_filename = hf_hub_download(

  File "/opt/conda/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)

  File "/opt/conda/lib/python3.9/site-packages/huggingface_hub/file_download.py", line 1159, in hf_hub_download
    os.makedirs(storage_folder, exist_ok=True)

  File "/opt/conda/lib/python3.9/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)

  File "/opt/conda/lib/python3.9/os.py", line 225, in makedirs
    mkdir(name, mode)

OSError: [Errno 30] Read-only file system: '/data'

Server is not up yet; status=000
[2m2024-04-08T21:09:54.611267Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Args { model_id: "codellama/CodeLlama-7b-Instruct-hf", revision: None, validation_workers: 2, sharded: None, num_shard: None, quantize: None, dtype: None, trust_remote_code: false, max_concurrent_requests: 128, max_best_of: 2, max_stop_sequences: 4, max_top_n_tokens: 5, max_input_length: 4000, max_total_tokens: 6000, waiting_served_ratio: 1.2, max_batch_prefill_tokens: 4096, max_batch_total_tokens: None, max_waiting_tokens: 20, hostname: "0.0.0.0", port: 8000, shard_uds_path: "/tmp/text-generation-server", master_addr: "localhost", master_port: 29500, huggingface_hub_cache: Some("/scratch/ms9761/rea-llm/data"), weights_cache_override: None, disable_custom_kernels: true, cuda_memory_fraction: 1.0, rope_scaling: None, rope_factor: None, json_output: false, otlp_endpoint: None, cors_allow_origin: [], watermark_gamma: None, watermark_delta: None, ngrok: false, ngrok_authtoken: None, ngrok_edge: None, env: false }
[2m2024-04-08T21:09:54.611369Z[0m [32m INFO[0m [1mdownload[0m: [2mtext_generation_launcher[0m[2m:[0m Starting download process.
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
[2m2024-04-08T21:10:01.065670Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Files are already present on the host. Skipping download.

Server is not up yet; status=000
[2m2024-04-08T21:10:02.026563Z[0m [32m INFO[0m [1mdownload[0m: [2mtext_generation_launcher[0m[2m:[0m Successfully downloaded weights.
[2m2024-04-08T21:10:02.026837Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Starting shard [2m[3mrank[0m[2m=[0m0[0m
Server is not up yet; status=000
Server is not up yet; status=000
[2m2024-04-08T21:10:04.648811Z[0m [33m WARN[0m [2mtext_generation_launcher[0m[2m:[0m We're not using custom kernels.

[2m2024-04-08T21:10:04.667602Z[0m [33m WARN[0m [2mtext_generation_launcher[0m[2m:[0m Unable to use Flash Attention V2: GPU with CUDA capability 7 5 is not supported for Flash Attention V2

[2m2024-04-08T21:10:04.703683Z[0m [33m WARN[0m [2mtext_generation_launcher[0m[2m:[0m Could not import Mistral model: Mistral model requires flash attn v2

Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
[2m2024-04-08T21:10:12.042175Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Waiting for shard to be ready... [2m[3mrank[0m[2m=[0m0[0m
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
[2m2024-04-08T21:10:21.285527Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Server started at unix:///tmp/text-generation-server-0

[2m2024-04-08T21:10:21.350974Z[0m [32m INFO[0m [1mshard-manager[0m: [2mtext_generation_launcher[0m[2m:[0m Shard ready in 19.322665295s [2m[3mrank[0m[2m=[0m0[0m
[2m2024-04-08T21:10:21.449446Z[0m [32m INFO[0m [2mtext_generation_launcher[0m[2m:[0m Starting Webserver
[2m2024-04-08T21:10:21.600612Z[0m [33m WARN[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m349:[0m `--revision` is not set
[2m2024-04-08T21:10:21.600652Z[0m [33m WARN[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m350:[0m We strongly advise to set it to a known supported commit.
[2m2024-04-08T21:10:21.748551Z[0m [32m INFO[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m371:[0m Serving revision 4ead8e64055f5ad41c6dd07e80ea9a2b76d8f174 of model codellama/CodeLlama-7b-Instruct-hf
[2m2024-04-08T21:10:21.764701Z[0m [32m INFO[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m213:[0m Warming up model
Server is not up yet; status=000
Server is not up yet; status=000
Server is not up yet; status=000
[2m2024-04-08T21:10:24.840313Z[0m [32m INFO[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m246:[0m Setting max batch total tokens to 62464
[2m2024-04-08T21:10:24.840327Z[0m [32m INFO[0m [2mtext_generation_router[0m[2m:[0m [2mrouter/src/main.rs[0m[2m:[0m[2m247:[0m Connected
Server is up!
HELLO FROM PYTHON
[2m2024-04-08T21:10:30.964779Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.219526488s" [3mvalidation_time[0m[2m=[0m"2.129132ms" [3mqueue_time[0m[2m=[0m"81.026Âµs" [3minference_time[0m[2m=[0m"3.217316493s" [3mtime_per_token[0m[2m=[0m"30.352041ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:34.059892Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.088942369s" [3mvalidation_time[0m[2m=[0m"528.355Âµs" [3mqueue_time[0m[2m=[0m"23.459Âµs" [3minference_time[0m[2m=[0m"3.088390821s" [3mtime_per_token[0m[2m=[0m"29.413245ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:36.354295Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.291678161s" [3mvalidation_time[0m[2m=[0m"437.339Âµs" [3mqueue_time[0m[2m=[0m"21.635Âµs" [3minference_time[0m[2m=[0m"2.291219292s" [3mtime_per_token[0m[2m=[0m"29.374605ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:37.249718Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"889.78217ms" [3mvalidation_time[0m[2m=[0m"469.104Âµs" [3mqueue_time[0m[2m=[0m"22.442Âµs" [3minference_time[0m[2m=[0m"889.290749ms" [3mtime_per_token[0m[2m=[0m"29.643024ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:39.835162Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.578017084s" [3mvalidation_time[0m[2m=[0m"642.651Âµs" [3mqueue_time[0m[2m=[0m"23.252Âµs" [3minference_time[0m[2m=[0m"2.577351407s" [3mtime_per_token[0m[2m=[0m"29.624728ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:41.395292Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"1.553736959s" [3mvalidation_time[0m[2m=[0m"387.948Âµs" [3mqueue_time[0m[2m=[0m"22.292Âµs" [3minference_time[0m[2m=[0m"1.55332682s" [3mtime_per_token[0m[2m=[0m"29.308052ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:44.103921Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.701807645s" [3mvalidation_time[0m[2m=[0m"444.539Âµs" [3mqueue_time[0m[2m=[0m"22.366Âµs" [3minference_time[0m[2m=[0m"2.701340847s" [3mtime_per_token[0m[2m=[0m"29.3624ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:46.610260Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.499824151s" [3mvalidation_time[0m[2m=[0m"809.508Âµs" [3mqueue_time[0m[2m=[0m"24.22Âµs" [3minference_time[0m[2m=[0m"2.498990526s" [3mtime_per_token[0m[2m=[0m"30.108319ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:48.471389Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"1.855631288s" [3mvalidation_time[0m[2m=[0m"720.017Âµs" [3mqueue_time[0m[2m=[0m"23.805Âµs" [3minference_time[0m[2m=[0m"1.854887556s" [3mtime_per_token[0m[2m=[0m"29.91754ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:50.331158Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"1.85720864s" [3mvalidation_time[0m[2m=[0m"692.466Âµs" [3mqueue_time[0m[2m=[0m"22.189Âµs" [3minference_time[0m[2m=[0m"1.856494147s" [3mtime_per_token[0m[2m=[0m"29.943453ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:52.977551Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.641127658s" [3mvalidation_time[0m[2m=[0m"431.918Âµs" [3mqueue_time[0m[2m=[0m"22.689Âµs" [3minference_time[0m[2m=[0m"2.640673198s" [3mtime_per_token[0m[2m=[0m"29.340813ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:54.481972Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"1.496095054s" [3mvalidation_time[0m[2m=[0m"399.671Âµs" [3mqueue_time[0m[2m=[0m"22.684Âµs" [3minference_time[0m[2m=[0m"1.49567288s" [3mtime_per_token[0m[2m=[0m"29.326919ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:56.041245Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"1.553848641s" [3mvalidation_time[0m[2m=[0m"416.112Âµs" [3mqueue_time[0m[2m=[0m"22.938Âµs" [3minference_time[0m[2m=[0m"1.553409778s" [3mtime_per_token[0m[2m=[0m"29.309617ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:10:58.700347Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.655362195s" [3mvalidation_time[0m[2m=[0m"565.6Âµs" [3mqueue_time[0m[2m=[0m"23.393Âµs" [3minference_time[0m[2m=[0m"2.654773301s" [3mtime_per_token[0m[2m=[0m"29.49748ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:11:01.359676Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.653179653s" [3mvalidation_time[0m[2m=[0m"552.414Âµs" [3mqueue_time[0m[2m=[0m"24.223Âµs" [3minference_time[0m[2m=[0m"2.652603121s" [3mtime_per_token[0m[2m=[0m"29.473367ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:11:04.018714Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.652833225s" [3mvalidation_time[0m[2m=[0m"564.735Âµs" [3mqueue_time[0m[2m=[0m"23.847Âµs" [3minference_time[0m[2m=[0m"2.652244792s" [3mtime_per_token[0m[2m=[0m"29.469386ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:11:06.677539Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.652800942s" [3mvalidation_time[0m[2m=[0m"547.284Âµs" [3mqueue_time[0m[2m=[0m"23.823Âµs" [3minference_time[0m[2m=[0m"2.652229945s" [3mtime_per_token[0m[2m=[0m"29.469221ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:11:11.116823Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"4.433049492s" [3mvalidation_time[0m[2m=[0m"731.882Âµs" [3mqueue_time[0m[2m=[0m"24.177Âµs" [3minference_time[0m[2m=[0m"4.432293592s" [3mtime_per_token[0m[2m=[0m"30.358175ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:11:13.455764Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"2.330686361s" [3mvalidation_time[0m[2m=[0m"537.757Âµs" [3mqueue_time[0m[2m=[0m"23.509Âµs" [3minference_time[0m[2m=[0m"2.330125247s" [3mtime_per_token[0m[2m=[0m"29.495255ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:11:16.673049Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.211984067s" [3mvalidation_time[0m[2m=[0m"871.908Âµs" [3mqueue_time[0m[2m=[0m"24.392Âµs" [3minference_time[0m[2m=[0m"3.211087946s" [3mtime_per_token[0m[2m=[0m"30.010167ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:12:20.825699Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"64.147324365s" [3mvalidation_time[0m[2m=[0m"553.278Âµs" [3mqueue_time[0m[2m=[0m"23.949Âµs" [3minference_time[0m[2m=[0m"64.146747315s" [3mtime_per_token[0m[2m=[0m"32.073373ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
[2m2024-04-08T21:12:24.585152Z[0m [32m INFO[0m [1mgenerate[0m[1m{[0m[3mparameters[0m[2m=[0mGenerateParameters { best_of: None, temperature: None, repetition_penalty: None, top_k: None, top_p: None, typical_p: None, do_sample: false, max_new_tokens: Some(2000), return_full_text: None, stop: [], truncate: None, watermark: false, details: false, decoder_input_details: false, seed: None, top_n_tokens: None } [3mtotal_time[0m[2m=[0m"3.753814999s" [3mvalidation_time[0m[2m=[0m"935.363Âµs" [3mqueue_time[0m[2m=[0m"24.798Âµs" [3minference_time[0m[2m=[0m"3.752855017s" [3mtime_per_token[0m[2m=[0m"30.02284ms" [3mseed[0m[2m=[0m"None"[1m}[0m[2m:[0m [2mtext_generation_router::server[0m[2m:[0m [2mrouter/src/server.rs[0m[2m:[0m[2m289:[0m Success
